{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02580fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
      "0        0.0            0.0      0.0         0.0  0.013889           0.0   \n",
      "1        1.0            0.0      1.0         0.0  0.472222           1.0   \n",
      "2        1.0            0.0      1.0         0.0  0.027778           1.0   \n",
      "3        1.0            0.0      1.0         0.0  0.625000           0.0   \n",
      "4        0.0            0.0      1.0         0.0  0.027778           1.0   \n",
      "...      ...            ...      ...         ...       ...           ...   \n",
      "7038     1.0            0.0      0.0         1.0  0.333333           1.0   \n",
      "7039     0.0            0.0      0.0         1.0  1.000000           1.0   \n",
      "7040     0.0            0.0      0.0         1.0  0.152778           0.0   \n",
      "7041     1.0            1.0      0.0         0.0  0.055556           1.0   \n",
      "7042     1.0            0.0      1.0         0.0  0.916667           1.0   \n",
      "\n",
      "      MultipleLines  InternetService  OnlineSecurity  OnlineBackup  \\\n",
      "0               1.0              2.0             2.0           2.0   \n",
      "1               2.0              2.0             2.0           1.0   \n",
      "2               2.0              2.0             2.0           2.0   \n",
      "3               1.0              2.0             2.0           1.0   \n",
      "4               2.0              1.0             2.0           1.0   \n",
      "...             ...              ...             ...           ...   \n",
      "7038            2.0              2.0             2.0           1.0   \n",
      "7039            2.0              1.0             2.0           2.0   \n",
      "7040            1.0              2.0             2.0           1.0   \n",
      "7041            2.0              1.0             2.0           1.0   \n",
      "7042            2.0              1.0             2.0           1.0   \n",
      "\n",
      "      DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n",
      "0                  2.0          1.0          1.0              1.0       1.0   \n",
      "1                  1.0          1.0          1.0              1.0       2.0   \n",
      "2                  2.0          1.0          1.0              1.0       1.0   \n",
      "3                  1.0          1.0          1.0              1.0       2.0   \n",
      "4                  2.0          1.0          1.0              1.0       1.0   \n",
      "...                ...          ...          ...              ...       ...   \n",
      "7038               1.0          1.0          1.0              1.0       2.0   \n",
      "7039               1.0          1.0          1.0              1.0       2.0   \n",
      "7040               2.0          1.0          1.0              1.0       1.0   \n",
      "7041               2.0          1.0          1.0              1.0       1.0   \n",
      "7042               1.0          1.0          1.0              1.0       2.0   \n",
      "\n",
      "      PaperlessBilling  PaymentMethod  MonthlyCharges  Churn  \n",
      "0                  0.0            3.0        0.115423    0.0  \n",
      "1                  1.0            3.0        0.385075    0.0  \n",
      "2                  0.0            3.0        0.354229    1.0  \n",
      "3                  1.0            2.0        0.239303    0.0  \n",
      "4                  0.0            3.0        0.521891    1.0  \n",
      "...                ...            ...             ...    ...  \n",
      "7038               0.0            3.0        0.662189    0.0  \n",
      "7039               0.0            1.0        0.845274    0.0  \n",
      "7040               0.0            3.0        0.112935    0.0  \n",
      "7041               0.0            3.0        0.558706    1.0  \n",
      "7042               0.0            2.0        0.869652    0.0  \n",
      "\n",
      "[7043 rows x 19 columns]\n",
      "Value Count  Counter({0.0: 4146, 1.0: 1488})\n",
      "Value Count  Counter({0.0: 1028, 1.0: 381})\n",
      "\n",
      "\n",
      "Train Set Info\n",
      "Accuracy: 0.646\n",
      "Recall: 0.865\n",
      "F1 Score: 0.563\n",
      "Precision: 0.418\n",
      "Specificity : 0.567\n",
      "False Discovery Rate : 0.582\n",
      "\n",
      "\n",
      "Test Set Info\n",
      "Accuracy: 0.270\n",
      "Recall: 1.000\n",
      "F1 Score: 0.426\n",
      "Precision: 0.270\n",
      "Specificity : 0.000\n",
      "False Discovery Rate : 0.730\n"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as copier\n",
    "import operator\n",
    "import collections\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "matrix=[]\n",
    "class Preprocessor:\n",
    "    def __init__(self, fileReader):\n",
    "        self.fileReader = fileReader\n",
    "        self.dataset = self.fileReader.readFromCSV()\n",
    "        self.dataframe=self.dataset\n",
    "        self.datamatrix=np.array(self.dataset)\n",
    "        self.datamatrix=np.transpose(self.datamatrix).tolist()\n",
    "        #print(self.dataframe.describe())\n",
    "        #print(\"Length of dataset \",len(self.dataset))\n",
    "        self.drop_column()\n",
    "        self.splitDataSet()\n",
    "        self.calculation()\n",
    "        #for column in self.dataframe.columns:\n",
    "            #print(\"Number of unique value \",column,\" \",len(pd.unique(self.dataframe[column])))\n",
    "        #self.count=self.dataframe['Churn'].value_counts()\n",
    "        #print(self.count)\n",
    "        #self.splitDataSet()\n",
    "        #print(self.dataframe.info())\n",
    "        #print(self.dataframe.loc[:,'Churn'])\n",
    "        \n",
    "    def drop_column(self):\n",
    "        #print(self.dataframe.head(10))\n",
    "        #self.uniquevalue = len(pd.unique(self.dataframe['Churn']))\n",
    "        #print(\"Number of churns : \",self.uniquevalue)\n",
    "        self.dataset_length=self.dataframe.shape[0]\n",
    "        for column in list(self.dataframe.columns):\n",
    "            self.col_length=len(pd.unique(self.dataframe[column]))\n",
    "            if(self.col_length>=self.dataset_length/2):\n",
    "                self.dataframe.drop([column],axis=1,inplace=True)\n",
    "            elif(self.col_length==1):\n",
    "                self.dataframe.drop([column],axis=1,inplace=True)\n",
    "        self.drop_row()\n",
    "        #self.categorical()\n",
    "        #print(self.dataframe)\n",
    "        \n",
    "        #for column in list(self.dataframe.columns):\n",
    "            #self.uniquevalue=len(pd.unique(self.dataframe[column]))\n",
    "            #print(column,\" \",self.uniquevalue,\" \",self.dataframe[column].dtypes)\n",
    "        #print(self.dataframe.isnull().sum())\n",
    "    \n",
    "    def drop_row(self):\n",
    "        for column in list(self.dataframe.columns):\n",
    "            muhaha=self.dataframe[column].tolist()\n",
    "        for x in muhaha:\n",
    "            if(x=='?' or x==' '):\n",
    "                x=np.nan\n",
    "        self.categorical()\n",
    "    \n",
    "    def categorical(self):\n",
    "        self.dataset_length=self.dataframe.shape[0]\n",
    "        for column in self.dataframe.columns:\n",
    "            if(self.dataframe[column].dtypes=='int64'):\n",
    "                self.dataframe[column]=self.dataframe[column].astype(float)\n",
    "            self.col_length=len(pd.unique(self.dataframe[column]))\n",
    "            if(self.col_length==2):\n",
    "                value_list=pd.unique(self.dataframe[column])\n",
    "                #print(value_list)\n",
    "                self.dataframe.loc[self.dataframe[column] ==value_list[0], column] = 0\n",
    "                self.dataframe.loc[self.dataframe[column] ==value_list[1], column] = 1\n",
    "                self.dataframe[column]=self.dataframe[column].astype(float)\n",
    "            elif(self.col_length<self.dataset_length/2 and self.dataframe[column].dtypes=='object' ):\n",
    "                value_list=pd.unique(self.dataframe[column])\n",
    "                for x in value_list:\n",
    "                    self.data_half=self.dataset_length//2\n",
    "                    self.dataframe.loc[self.dataframe[column] ==x, column] = random.randrange(1.0,len(value_list))\n",
    "                self.dataframe[column]=self.dataframe[column].astype(float)\n",
    "            elif(self.col_length<self.dataset_length/2 and self.dataframe[column].dtypes=='float64' ):\n",
    "                self.dataframe[column] = (self.dataframe[column] - self.dataframe[column].min()) / (self.dataframe[column].max() - self.dataframe[column].min())    \n",
    "                \n",
    "            #print(\"Number of unique value \",column,\" \",len(pd.unique(self.dataframe[column])))\n",
    "            #print(column,\" \",self.dataframe.info())\n",
    "        #print(self.dataframe.info())\n",
    "        #print(np.array(self.dataframe))\n",
    "        #print(self.dataframe)\n",
    "        \n",
    "        print(self.dataframe)\n",
    "        self.datamatrix=(np.array(self.dataframe))\n",
    "        row, col = self.datamatrix.shape\n",
    "        self.datamatrix_with_label=self.datamatrix[:,-1]\n",
    "        self.actual_class=self.datamatrix_with_label\n",
    "        self.datamatrix_no_label = np.delete(self.datamatrix, -1, axis=1)\n",
    "        row, col = np.transpose(self.datamatrix_no_label).shape\n",
    "        #print(row,\" \",col)\n",
    "        #print(self.datamatrix_no_label)\n",
    "        #print(self.datamatrix_with_label)\n",
    "        self.datamatrix_transpose=np.transpose(self.datamatrix)      \n",
    "        #print(self.datamatrix_transpose)\n",
    "        #print(len(self.datamatrix_transpose))\n",
    "        #print(self.dataframe.iloc[:,17])\n",
    "        #print(self.datamatrix)\n",
    "        row, col = self.datamatrix_no_label.shape\n",
    "        self.w=np.ones((col+1))\n",
    "    def splitDataSet(self):\n",
    "        self.datamatrix=np.array(self.dataframe)\n",
    "        #trans = np.transpose(self.datamatrix).tolist()\n",
    "        #print(trans)\n",
    "        train, test = train_test_split(self.dataset, test_size=0.2)\n",
    "        self.test = test\n",
    "        self.train = train\n",
    "        self.train_matrix=np.array(self.train)\n",
    "        self.test_matrix=np.array(self.test)\n",
    "        self.train_matrix_x=np.delete(self.train_matrix, -1, axis=1)\n",
    "        self.train_matrix_y=self.train_matrix[:,-1]\n",
    "        self.test_matrix_x=np.delete(self.test_matrix, -1, axis=1)\n",
    "        self.test_matrix_y=self.test_matrix[0:,-1]\n",
    "        print(\"Value Count \",collections.Counter(self.train_matrix_y))\n",
    "        print(\"Value Count \",collections.Counter(self.test_matrix_y))\n",
    "        print('\\n')\n",
    "        #print(\"TestX \",self.test_matrix_x)\n",
    "        #print(\"TestY \",self.test_matrix_y)\n",
    "        #print(\"TrainX \",self.train_matrix_x)\n",
    "        #print(\"TrainY \",self.train_matrix_y)\n",
    "        #print(\"Train \",self.train_matrix)\n",
    "        #print('\\n')\n",
    "        #print(\"Test \",self.test_matrix)\n",
    "        #print(\"length Train \",len(self.train))\n",
    "        #print(\"Length test \",len(self.test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def tanh(self,z):\n",
    "        x=(np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\n",
    "        #print(\"tanh \",x)\n",
    "        return (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\n",
    "        #return 1 / (1 + np.exp(-z))\n",
    "    def hx(self,w,x):\n",
    "        row, col = self.datamatrix_no_label.shape\n",
    "        z=w[0]\n",
    "        result_z=np.zeros((col))\n",
    "        for i in range(0,col):\n",
    "            z=z+w[i+1]*x[:,i]\n",
    "        result_z=np.array(z)\n",
    "        #norm = np.linalg.norm(result_z)\n",
    "        #result_z = result_z/norm\n",
    "        #print(\"Result \",result_z)\n",
    "        return self.tanh(result_z)\n",
    "        #print(result_z)\n",
    "        #print(self.tanh(result_z))\n",
    "        \n",
    "    def cost(self,w, X, Y):\n",
    "        #w = [element * (-1) for element in w]\n",
    "        #print(\"In cost \",w)\n",
    "        self.y_pred = self.hx(w,X)\n",
    "        #print(type(self.y_pred))\n",
    "        #print(\"Predicted Y value \",self.y_pred)\n",
    "        #print(\"Predicted Y From cost Function \",self.y_pred)\n",
    "        return -1 * sum(Y*np.log(self.y_pred+1.0001) + (1-Y)*np.log(1-self.y_pred+1.0001))\n",
    "    def grad(self,w, X, Y):\n",
    "        self.y_pred = self.hx(w,X)\n",
    "        row, col = self.datamatrix_no_label.shape\n",
    "        g = list()\n",
    "        g.append( (-1*sum(Y*(1-self.y_pred)-(1-Y)*self.y_pred)))\n",
    "        for i in range(0,col):\n",
    "            g.append(-1 * sum(Y*(1-self.y_pred)*X[:,i] - (1-Y)*self.y_pred*X[:,i]))\n",
    "        return g\n",
    "    \n",
    "    def descent(self,w_prev, lr):\n",
    "        #print(\"W Prev \",w_prev)\n",
    "        #print(\"Cost Prev \\n\",self.cost(w_prev, self.datamatrix_no_label, self.datamatrix_with_label))\n",
    "        j=0\n",
    "        dummy=0\n",
    "        row, col = self.datamatrix_no_label.shape\n",
    "        w_new_list=list()\n",
    "        w_new_list1=list()\n",
    "        w_new=np.ones(col+1)\n",
    "        w_new1=np.ones(col+1)\n",
    "        while True:\n",
    "            w_prev = w_new\n",
    "            w_prev1=w_new1\n",
    "            w_new_list.clear()\n",
    "            w_new_list1.clear()\n",
    "            for i in range(0,col+1):\n",
    "                dummy=w_prev[i]-lr*self.grad(w_prev,self.train_matrix_x,self.train_matrix_y)[i]\n",
    "                dummy1=w_prev1[i]-lr*self.grad(w_prev,self.test_matrix_x,self.test_matrix_y)[i]\n",
    "                w_new_list.append(dummy)\n",
    "                w_new_list1.append(dummy1)\n",
    "            w_new=np.array(w_new_list)\n",
    "            w_new1=np.array(w_new_list1)\n",
    "            #print(\"Length of wnew \",len(w_new))\n",
    "            #print(\"W-new after \",j,\"th iteration \",w_new)\n",
    "            w_new_first=w_new[0]\n",
    "            w_new_first1=w_new1[0]\n",
    "            w_new_t=np.delete(w_new,0)\n",
    "            w_new_t1=np.delete(w_new1,0)\n",
    "            #print(\"W-new after deleting w0 \",w_new_t)\n",
    "            w_new_2d=np.reshape(w_new_t,(col,1))\n",
    "            w_new_2d_transpose=np.transpose(w_new_2d)\n",
    "            w_new_2d1=np.reshape(w_new_t1,(col,1))\n",
    "            w_new_2d_transpose1=np.transpose(w_new_2d1)\n",
    "            #print(\"W in matrix transpose \",w_new_2d_transpose)\n",
    "            #self.decision=np.dot(w_new_2d_transpose,np.transpose(self.train_matrix_x))\n",
    "            self.decision=np.dot(w_new_2d_transpose,np.transpose(self.train_matrix_x))\n",
    "            self.decision1=np.dot(w_new_2d_transpose1,np.transpose(self.test_matrix_x))\n",
    "            self.decision=w_new_first+self.decision\n",
    "            self.decision1=w_new_first1+self.decision1\n",
    "            #print(\" Decision \",self.decision)\n",
    "            #norm = np.linalg.norm(self.decision)\n",
    "            #self.decision = self.decision/norm\n",
    "            self.decision_sigmoid=self.tanh(self.decision)\n",
    "            self.decision_sigmoid1=self.tanh(self.decision1)\n",
    "            #print(\"Sigmoid \",self.tanh(self.decision))\n",
    "            #print(\"Sigmoid \",self.decision_sigmoid)\n",
    "            #print(\"Sigmoid len \",self.decision_sigmoid.shape)\n",
    "            #print(\"Min \",np.min(self.decision_sigmoid))\n",
    "            #print(\"Max \",np.max(self.decision_sigmoid))\n",
    "            #self.splitDataSet()\n",
    "            #print(\"Cost-new after \",j,\"th iteration \",self.cost(w_new, self.datamatrix_no_label, self.datamatrix_with_label))\n",
    "            #self.cost(w_new, self.datamatrix_no_label,self.datamatrix_with_label)\n",
    "            if j>9: \n",
    "                #return w_new\n",
    "                break\n",
    "            j+=1\n",
    "            \n",
    "    def calculation(self):\n",
    "        row, col = self.datamatrix_no_label.shape\n",
    "        #row_train,col_train=self.train_matrix_x.shape\n",
    "        self.w=np.ones((col+1))\n",
    "        self.w1=np.ones((col+1))\n",
    "        #self.w=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "        #self.w=self.descent(self.w,.099)\n",
    "        self.descent(self.w,0.00099)\n",
    "        self.descent(self.w1,.00099)\n",
    "        #print(\"Predicted Y : \",self.y_pred)\n",
    "        #print(\"After multiplication \",self.y_pred)\n",
    "        #self.y_pred =  [abs(ele) for ele in self.y_pred]\n",
    "        #print(\"After abs value \",self.y_pred)\n",
    "        #print(\"Min \",np.min(self.decision*10))\n",
    "        #print(\"Max \",np.max(self.decision*10))\n",
    "        #self.decision*=10\n",
    "        self._count=0\n",
    "        self.count=0\n",
    "        row_decision,col_decision=self.decision.shape\n",
    "        row_decision1,col_decision1=self.decision1.shape\n",
    "        self.min_sigmoid=np.min(self.decision_sigmoid)\n",
    "        self.min_sigmoid1=np.min(self.decision_sigmoid1)\n",
    "        #self.min_sigmoid=round(self.min_sigmoid,6)\n",
    "        self.max_sigmoid=np.max(self.decision_sigmoid)\n",
    "        self.max_sigmoid1=np.max(self.decision_sigmoid1)\n",
    "        #self.max_sigmoid=round(self.max_sigmoid,6)\n",
    "        self.avg=(self.min_sigmoid+self.max_sigmoid)/2\n",
    "        self.avg1=(self.min_sigmoid1+self.max_sigmoid1)/2\n",
    "        self.avg=round(self.avg,15)\n",
    "        self.avg1=round(self.avg1,15)\n",
    "        self.predicted_list=list()\n",
    "        self.predicted_list1=list()\n",
    "        if(self.avg<0):\n",
    "            self.avg*=-1\n",
    "        #print(self.min_sigmoid,\" \",self.max_sigmoid,\" \",self.avg)\n",
    "        for i in range(0,row_decision):\n",
    "            for j in range(0,col_decision):\n",
    "                if(self.decision[i][j]<self.avg):\n",
    "                    self._count+=1\n",
    "                    self.predicted_list.append(0)\n",
    "                elif(self.decision[i][j]>=self.avg):\n",
    "                    self.count+=1\n",
    "                    self.predicted_list.append(1)\n",
    "        self.predicted_class=np.array(self.predicted_list)\n",
    "        self._count=0\n",
    "        self.count=0\n",
    "        \n",
    "        if(self.avg1<0):\n",
    "            self.avg1*=-1\n",
    "        #print(self.min_sigmoid,\" \",self.max_sigmoid,\" \",self.avg)\n",
    "        for i in range(0,row_decision1):\n",
    "            for j in range(0,col_decision1):\n",
    "                if(self.decision1[i][j]<self.avg1):\n",
    "                    self._count+=1\n",
    "                    self.predicted_list1.append(0)\n",
    "                elif(self.decision1[i][j]>=self.avg1):\n",
    "                    self.count+=1\n",
    "                    self.predicted_list1.append(1)\n",
    "        self.predicted_class1=np.array(self.predicted_list1)\n",
    "        \n",
    "            \n",
    "        print(\"Train Set Info\")\n",
    "        print('Accuracy: %.3f' % accuracy_score(self.train_matrix_y, self.predicted_class))\n",
    "        print('Recall: %.3f' % recall_score(self.train_matrix_y, self.predicted_class))\n",
    "        print('F1 Score: %.3f' % f1_score(self.train_matrix_y, self.predicted_class))\n",
    "        print('Precision: %.3f' % precision_score(self.train_matrix_y, self.predicted_class))\n",
    "        tn, fp, fn, tp = confusion_matrix(self.train_matrix_y, self.predicted_class).ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "        false_discovery_rate=fp/(fp+tp)\n",
    "        print('Specificity : %.3f' % specificity)\n",
    "        print('False Discovery Rate : %.3f'% false_discovery_rate)\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "        print(\"Test Set Info\")\n",
    "        print('Accuracy: %.3f' % accuracy_score(self.test_matrix_y, self.predicted_class1))\n",
    "        print('Recall: %.3f' % recall_score(self.test_matrix_y, self.predicted_class1))\n",
    "        print('F1 Score: %.3f' % f1_score(self.test_matrix_y, self.predicted_class1))\n",
    "        print('Precision: %.3f' % precision_score(self.test_matrix_y, self.predicted_class1))\n",
    "        tn, fp, fn, tp = confusion_matrix(self.test_matrix_y, self.predicted_class1).ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "        false_discovery_rate=fp/(fp+tp)\n",
    "        print('Specificity : %.3f' % specificity)\n",
    "        print('False Discovery Rate : %.3f'% false_discovery_rate)\n",
    "        #print(\"Weight\\n\",self.w)\n",
    "        #print(len(self.w))\n",
    "        \n",
    "class FileReader:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def readFromCSV(self):\n",
    "        csvParser = pd.read_csv(self.filename)\n",
    "        return csvParser\n",
    "\n",
    "    \"\"\"\"def readFromTXT(self):\n",
    "        testDataFile = open(self.filename, \"r\")\n",
    "        lines = [line.strip().split() for line in testDataFile]\n",
    "        testDataFile.close()\n",
    "        print (lines)\n",
    "        return lines\n",
    "    def readFromData(self):\n",
    "        testDataFile = open(self.filename, \"r\")\n",
    "        lines = [line.strip().split() for line in testDataFile]\n",
    "        testDataFile.close()\n",
    "        return lines\n",
    "\n",
    "    def readFromTest(self):\n",
    "        testDataFile = open(self.filename, \"r\")\n",
    "        lines = [line.strip().split() for line in testDataFile]\n",
    "        testDataFile.close()\n",
    "        return lines[1:]\n",
    "\"\"\"\n",
    "    def getCSV(self):\n",
    "        return self.csvData\n",
    "files=[\"telco_customer.csv\"]\n",
    "#files=[\"creditcard.csv\"]\n",
    "#files=[\"adult.csv\"]\n",
    "for file in files:\n",
    "    preprocessor=Preprocessor(FileReader(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b13770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
